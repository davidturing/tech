#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
é¡¹ç›®1: æ¢ç´¢æ€§æ•°æ®åˆ†æ (EDA) - å…¨çƒAIå‘å±•è¶‹åŠ¿åˆ†æ
å­¦ç”Ÿç¤ºä¾‹ä»£ç 
ä½œè€…: å¼ æ˜ (985é«˜æ ¡å·¥ç§‘å¤§äºŒå­¦ç”Ÿ)
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import warnings
warnings.filterwarnings('ignore')

# è®¾ç½®ä¸­æ–‡å­—ä½“å’Œæ ·å¼
plt.rcParams['font.sans-serif'] = ['SimHei']
plt.rcParams['axes.unicode_minus'] = False
sns.set_style("whitegrid")

def load_and_explore_data():
    """æ•°æ®åŠ è½½ä¸åˆæ­¥æ¢ç´¢"""
    print("=== æ•°æ®åŠ è½½ä¸æ¢ç´¢ ===")
    
    # åˆ›å»ºæ¨¡æ‹Ÿæ•°æ®ï¼ˆå®é™…é¡¹ç›®ä¸­ä¼šä»CSVæ–‡ä»¶åŠ è½½ï¼‰
    np.random.seed(42)
    countries = ['ä¸­å›½', 'ç¾å›½', 'è‹±å›½', 'å¾·å›½', 'æ—¥æœ¬', 'éŸ©å›½', 'æ³•å›½', 'åŠ æ‹¿å¤§', 'æ¾³å¤§åˆ©äºš', 'å°åº¦']
    years = list(range(2020, 2027))
    
    data = []
    for country in countries:
        base_investment = np.random.uniform(100, 1000)
        base_patents = np.random.randint(50, 500)
        base_talent = np.random.randint(1000, 10000)
        base_companies = np.random.randint(10, 100)
        gov_support = np.random.uniform(5, 9)
        
        for year in years:
            # æ¨¡æ‹Ÿé€å¹´å¢é•¿è¶‹åŠ¿
            growth_factor = 1.1 ** (year - 2020)
            investment = base_investment * growth_factor + np.random.normal(0, 50)
            patents = int(base_patents * growth_factor + np.random.normal(0, 20))
            talent = int(base_talent * growth_factor + np.random.normal(0, 100))
            companies = int(base_companies * growth_factor + np.random.normal(0, 5))
            
            data.append({
                'country': country,
                'year': year,
                'ai_investment_millions': max(0, investment),
                'ai_patents': max(0, patents),
                'ai_talent_count': max(0, talent),
                'ai_companies': max(0, companies),
                'government_support_score': gov_support
            })
    
    df = pd.DataFrame(data)
    
    # æ·»åŠ ä¸€äº›ç¼ºå¤±å€¼å’Œå¼‚å¸¸å€¼ç”¨äºæ¼”ç¤ºæ¸…æ´—è¿‡ç¨‹
    df.loc[df.sample(frac=0.05).index, 'ai_investment_millions'] = np.nan
    df.loc[df.sample(frac=0.03).index, 'ai_patents'] = -1  # å¼‚å¸¸å€¼
    
    print(f"æ•°æ®å½¢çŠ¶: {df.shape}")
    print(f"æ•°æ®åŸºæœ¬ä¿¡æ¯:")
    print(df.info())
    print(f"\næ•°å€¼åˆ—ç»Ÿè®¡æ‘˜è¦:")
    print(df.describe())
    
    return df

def clean_data(df):
    """æ•°æ®æ¸…æ´—"""
    print("\n=== æ•°æ®æ¸…æ´— ===")
    
    # 1. å¤„ç†ç¼ºå¤±å€¼
    print(f"ç¼ºå¤±å€¼ç»Ÿè®¡:")
    print(df.isnull().sum())
    
    # ä½¿ç”¨å‰å‘å¡«å……å¤„ç†æŠ•èµ„é‡‘é¢çš„ç¼ºå¤±å€¼
    df['ai_investment_millions'] = df.groupby('country')['ai_investment_millions'].fillna(method='ffill')
    
    # å¯¹äºä»ç„¶å­˜åœ¨çš„ç¼ºå¤±å€¼ï¼Œä½¿ç”¨å›½å®¶å¹³å‡å€¼å¡«å……
    country_means = df.groupby('country')['ai_investment_millions'].mean()
    for country in df['country'].unique():
        mask = (df['country'] == country) & (df['ai_investment_millions'].isnull())
        df.loc[mask, 'ai_investment_millions'] = country_means[country]
    
    # 2. å¤„ç†å¼‚å¸¸å€¼
    print(f"\nå¼‚å¸¸å€¼å¤„ç†å‰ - AIä¸“åˆ©æœ€å°å€¼: {df['ai_patents'].min()}")
    df.loc[df['ai_patents'] < 0, 'ai_patents'] = 0
    print(f"å¼‚å¸¸å€¼å¤„ç†å - AIä¸“åˆ©æœ€å°å€¼: {df['ai_patents'].min()}")
    
    # 3. æ•°æ®ç±»å‹ä¼˜åŒ–
    df['year'] = df['year'].astype('int32')
    df['ai_investment_millions'] = df['ai_investment_millions'].astype('float32')
    df['ai_patents'] = df['ai_patents'].astype('int32')
    df['ai_talent_count'] = df['ai_talent_count'].astype('int32')
    df['ai_companies'] = df['ai_companies'].astype('int32')
    
    print(f"\næ¸…æ´—åæ•°æ®å½¢çŠ¶: {df.shape}")
    print(f"æ¸…æ´—åç¼ºå¤±å€¼: {df.isnull().sum().sum()}")
    
    return df

def basic_analysis(df):
    """åŸºç¡€åˆ†æ"""
    print("\n=== åŸºç¡€åˆ†æ ===")
    
    # 1. è®¡ç®—å„å›½AIæŠ•èµ„çš„å¹´å¢é•¿ç‡
    df_sorted = df.sort_values(['country', 'year'])
    df_sorted['investment_growth'] = df_sorted.groupby('country')['ai_investment_millions'].pct_change()
    df_sorted['investment_growth'] = df_sorted['investment_growth'].fillna(0)
    
    print(f"å„å›½AIæŠ•èµ„å¹´å‡å¢é•¿ç‡ (2020-2026):")
    growth_by_country = df_sorted.groupby('country')['investment_growth'].mean()
    print(growth_by_country.sort_values(ascending=False))
    
    # 2. æ‰¾å‡ºAIäººæ‰å¯†åº¦æœ€é«˜çš„å‰10ä¸ªå›½å®¶
    # è¿™é‡Œç®€åŒ–ä¸ºç›´æ¥æŒ‰äººæ‰æ•°é‡æ’åºï¼ˆå®é™…é¡¹ç›®ä¸­ä¼šè€ƒè™‘äººå£ç­‰å› ç´ ï¼‰
    talent_by_country = df[df['year'] == 2026].groupby('country')['ai_talent_count'].mean()
    print(f"\nAIäººæ‰æ•°é‡æœ€å¤šçš„å‰5ä¸ªå›½å®¶ (2026å¹´):")
    print(talent_by_country.sort_values(ascending=False).head())
    
    # 3. åˆ†ææ”¿åºœæ”¯æŒåº¦ä¸AIæŠ•èµ„çš„ç›¸å…³æ€§
    correlation = df[['government_support_score', 'ai_investment_millions']].corr().iloc[0, 1]
    print(f"\næ”¿åºœæ”¯æŒåº¦ä¸AIæŠ•èµ„çš„ç›¸å…³ç³»æ•°: {correlation:.3f}")
    
    return df_sorted

def create_visualizations(df):
    """åˆ›å»ºå¯è§†åŒ–"""
    print("\n=== å¯è§†åŒ–ç”Ÿæˆ ===")
    
    # 1. æ—¶é—´åºåˆ—å›¾å±•ç¤ºå…¨çƒAIæŠ•èµ„è¶‹åŠ¿
    global_investment = df.groupby('year')['ai_investment_millions'].sum().reset_index()
    
    fig1 = px.line(global_investment, x='year', y='ai_investment_millions',
                   title='å…¨çƒAIæŠ•èµ„è¶‹åŠ¿ (2020-2026)',
                   labels={'ai_investment_millions': 'AIæŠ•èµ„é‡‘é¢ (ç™¾ä¸‡ç¾å…ƒ)', 'year': 'å¹´ä»½'})
    fig1.write_html("global_ai_investment_trend.html")
    print("å·²ä¿å­˜: global_ai_investment_trend.html")
    
    # 2. çƒ­åŠ›å›¾æ˜¾ç¤ºå„å›½AIå‘å±•æŒ‡æ ‡ç›¸å…³æ€§
    numeric_cols = ['ai_investment_millions', 'ai_patents', 'ai_talent_count', 'ai_companies', 'government_support_score']
    correlation_matrix = df[numeric_cols].corr()
    
    fig2 = px.imshow(correlation_matrix, 
                     labels=dict(color="ç›¸å…³ç³»æ•°"),
                     title="AIå‘å±•æŒ‡æ ‡ç›¸å…³æ€§çƒ­åŠ›å›¾",
                     color_continuous_scale='RdBu_r')
    fig2.write_html("ai_correlation_heatmap.html")
    print("å·²ä¿å­˜: ai_correlation_heatmap.html")
    
    # 3. æ•£ç‚¹å›¾çŸ©é˜µå±•ç¤ºå¤šå˜é‡å…³ç³»
    sample_df = df[df['year'] == 2026].sample(n=min(100, len(df)), random_state=42)
    
    fig3 = px.scatter_matrix(sample_df, 
                            dimensions=['ai_investment_millions', 'ai_patents', 'ai_talent_count', 'government_support_score'],
                            color='country',
                            title="AIå‘å±•æŒ‡æ ‡æ•£ç‚¹å›¾çŸ©é˜µ (2026å¹´)")
    fig3.update_traces(diagonal_visible=False)
    fig3.write_html("ai_scatter_matrix.html")
    print("å·²ä¿å­˜: ai_scatter_matrix.html")
    
    # 4. åœ°ç†å¯è§†åŒ– - äº¤äº’å¼ä¸–ç•Œåœ°å›¾
    latest_data = df[df['year'] == 2026].groupby('country').first().reset_index()
    
    # åˆ›å»ºå›½å®¶ä»£ç æ˜ å°„ï¼ˆç®€åŒ–ç‰ˆï¼‰
    country_codes = {
        'ä¸­å›½': 'CHN', 'ç¾å›½': 'USA', 'è‹±å›½': 'GBR', 'å¾·å›½': 'DEU', 'æ—¥æœ¬': 'JPN',
        'éŸ©å›½': 'KOR', 'æ³•å›½': 'FRA', 'åŠ æ‹¿å¤§': 'CAN', 'æ¾³å¤§åˆ©äºš': 'AUS', 'å°åº¦': 'IND'
    }
    latest_data['country_code'] = latest_data['country'].map(country_codes)
    
    fig4 = px.choropleth(latest_data, 
                        locations='country_code',
                        color='ai_investment_millions',
                        hover_name='country',
                        hover_data=['ai_talent_count', 'ai_companies', 'government_support_score'],
                        color_continuous_scale='Viridis',
                        title='2026å¹´å„å›½AIæŠ•èµ„åˆ†å¸ƒ')
    fig4.write_html("ai_investment_world_map.html")
    print("å·²ä¿å­˜: ai_investment_world_map.html")
    
    return True

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¼€å§‹æ‰§è¡Œé¡¹ç›®1: æ¢ç´¢æ€§æ•°æ®åˆ†æ (EDA) - å…¨çƒAIå‘å±•è¶‹åŠ¿åˆ†æ")
    
    # 1. æ•°æ®åŠ è½½ä¸æ¢ç´¢
    df = load_and_explore_data()
    
    # 2. æ•°æ®æ¸…æ´—
    df_clean = clean_data(df)
    
    # 3. åŸºç¡€åˆ†æ
    df_analyzed = basic_analysis(df_clean)
    
    # 4. å¯è§†åŒ–
    create_visualizations(df_clean)
    
    # 5. ä¿å­˜æ¸…æ´—åçš„æ•°æ®
    df_clean.to_csv("cleaned_ai_trends_data.csv", index=False)
    print("\nâœ… å·²ä¿å­˜æ¸…æ´—åçš„æ•°æ®: cleaned_ai_trends_data.csv")
    
    print("\nğŸ‰ é¡¹ç›®1æ‰§è¡Œå®Œæˆï¼æ‰€æœ‰è¾“å‡ºæ–‡ä»¶å·²ä¿å­˜åˆ°å½“å‰ç›®å½•ã€‚")
    print("ğŸ“‹ ç”Ÿæˆçš„æ–‡ä»¶åŒ…æ‹¬:")
    print("   - cleaned_ai_trends_data.csv")
    print("   - global_ai_investment_trend.html")  
    print("   - ai_correlation_heatmap.html")
    print("   - ai_scatter_matrix.html")
    print("   - ai_investment_world_map.html")

if __name__ == "__main__":
    main()